{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1799d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import codecs\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca38df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Eligio/Documents/NPEC/NEAT/02.DataCollection')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('.').absolute()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7fca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "flist = ['1. Collected_data-China_testc1_modisa.csv', \n",
    "         '2. Collected_data-Korea_red_tite_south_sea(2018-2019)_UTC.csv',\n",
    "         '2. Collected_data-Korea_wave_glider_in_situ_data.csv',\n",
    "         '3. Collected_data-Russia_VKachur_chl_a_new.csv',\n",
    "         '3. Collected_data-Russia_VKachur_chl_OC2.csv',\n",
    "         '3. Collected_data-Russia_VKachur_Rrs.csv', 'Toyama_data2003-2021.xls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d705b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def china(file: str):\n",
    "    dataset = pd.read_csv(path.joinpath(file))\n",
    "    dataset.rename(columns={col:col.lower() \n",
    "                            for col in dataset.columns}, \n",
    "                   inplace=True)\n",
    "    dataset.insert(1, 'country', 'China')\n",
    "    return dataset.set_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c35bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def korea(file: str):\n",
    "    ds = pd.read_csv(path.joinpath(file))\n",
    "    if 'red_tite' in file:\n",
    "        ds.rename(columns={'time(UTC)':'time'}, inplace=True)\n",
    "        ds.insert(1, 'country', 'Korea')\n",
    "        return ds.set_index(index)\n",
    "    \n",
    "    if 'wave_glider' in file:\n",
    "        dates, times = [], []\n",
    "        append = dates.append\n",
    "        appent = times.append\n",
    "        \n",
    "        drop_cols = ['Year', 'Month', 'Day', 'Hour', 'Minute'] + [\n",
    "            col for col in ds.columns if 'Unnamed' in col\n",
    "        ]\n",
    "        for y, m, d, h, mn in zip(ds.loc[: ,'Year'], \n",
    "                                  ds.loc[: ,'Month'],\n",
    "                                  ds.loc[: ,'Day'],\n",
    "                                  ds.loc[: ,'Hour'], \n",
    "                                  ds.loc[: ,'Minute']):\n",
    "            # date = pd.to_datetime(f'{y}-{d:02}-{m:02} {h:02}:{mn:02}')\n",
    "            append(f'{m:g}/{d:g}/{y}')\n",
    "            appent(f'{h:g}:{mn:02}')\n",
    "        \n",
    "        sta = [f'WG{i+1}' for i in range(ds.shape[0])]\n",
    "        ds.insert(0, 'station', sta)\n",
    "        ds.insert(1, 'country', 'Korea')\n",
    "        ds.insert(2, 'date', dates)\n",
    "        ds.insert(3, 'time', times)\n",
    "        ds.drop(columns=drop_cols, inplace=True)\n",
    "        \n",
    "        ds.rename(columns={'Longitude':'lon', \n",
    "                           'Latitude': 'lat', \n",
    "                           'Chlorophyll-a': 'chla'}, inplace=True)\n",
    "        return ds.set_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d354d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def japan(file: str):\n",
    "    ds = pd.read_excel(path.joinpath(file), sheet_name='Sheet2', parse_dates=False)\n",
    "    cols = {col:col.replace('Rrs', 'Rrs_') for col in ds.columns}\n",
    "    ds.sort_values('date', axis=0, ascending=True, inplace=True)\n",
    "    ds.sort_values('date', axis=0, ascending=True, inplace=True)\n",
    "    ds.dropna(axis=0, subset=['date', 'time'], inplace=True)\n",
    "    \n",
    "    ds['date'] = [fmt_date(date_str=d, sep='-') for d in ds['date']]\n",
    "    ds['time'] = [fmt_time(time_str=t) for t in ds['time']]\n",
    "    ds.rename(columns=cols, inplace=True)\n",
    "    ds.replace(np.nan, '-999', inplace=True)\n",
    "    return ds.set_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b7048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_time(time_str: str, sep: str = ':'):\n",
    "    # print(time_str, type(time_str))\n",
    "    if type(time_str) == str:\n",
    "        h, m, s = time_str.split(sep)\n",
    "    else:\n",
    "        h, m = time_str.strftime(f'%H{sep}%M').split(sep)\n",
    "    return f'{int(h)}{sep}{int(m):02}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c2c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_date(date_str: str, sep: str = '/'):\n",
    "    # print(date_str, type(date_str))\n",
    "    if type(date_str) == str:\n",
    "        m, d, y = date_str.split(sep)\n",
    "    else:\n",
    "        m, d, y = date_str.strftime(f'%m{sep}%d{sep}%Y').split(sep)\n",
    "    return f'{int(m)}/{int(d)}/{int(y)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e836734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russia(file: str):\n",
    "    dataset = pd.read_csv(path.joinpath(file))\n",
    "    if 'Rrs' in file:\n",
    "        dataset['date'] = [fmt_date(date_str=d) for d in dataset['date']]     \n",
    "    dataset.insert(1, 'country', 'Russia')\n",
    "    return dataset.set_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80fa114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pd(left=None, right=None, top=None, bottom=None):\n",
    "    if left is None:\n",
    "        return top.append(other=bottom)\n",
    "    if top is None:\n",
    "        return left.merge(right, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db879349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebac879c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: (57, 1)\n",
      "2: (1426, 1)\n",
      "3: (1544, 1)\n",
      "3: (1813, 2)\n",
      "3: (1813, 293)\n",
      "T: (2858, 301)\n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "index = ['country', 'date', 'time', 'lat', 'lon', 'station']\n",
    "for i, f in enumerate(flist):\n",
    "        \n",
    "    if df is None:\n",
    "        df = china(file=f)\n",
    "        continue\n",
    "        \n",
    "    if i < 5:\n",
    "        if int(f[0]) == 2:\n",
    "            dfi = korea(file=f)\n",
    "        if int(f[0]) == 3:\n",
    "            dfi = russia(file=f)\n",
    "        df = merge_pd(top=df, bottom=dfi)\n",
    "        \n",
    "    if i == 5:\n",
    "        dfi = russia(file=f)\n",
    "        df = merge_pd(left=df, right=dfi)\n",
    "        \n",
    "    if not f[0].isdigit():\n",
    "        dfi = japan(file=f)\n",
    "        df = merge_pd(top=df, bottom=dfi)\n",
    "        cols = [col for col in df.columns if 'Rrs_' not in col] + sorted(\n",
    "            [col for col in df.columns if 'Rrs_' in col]\n",
    "        )\n",
    "        df = df.loc[:, cols]\n",
    "    print(f'{f[0]}: {df.shape}')\n",
    "df.replace(np.nan, '-999', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d586f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstr = datetime.today().strftime('%Y%m%d')\n",
    "f = f'insitu_data_collection_{dstr}.csv'\n",
    "df.to_csv(f, float_format='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "485eb86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_output(iterator: iter):\n",
    "    result = []\n",
    "    append = result.append\n",
    "    for ln, hd in iterator:\n",
    "        if (hd in index) or (ln in ('-999', 999)):\n",
    "            append(ln)\n",
    "            continue\n",
    "        try:\n",
    "            append(f'{float(ln):.6f}')\n",
    "        except ValueError:\n",
    "            append('-999')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63eeed0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split = '\\r\\n'\n",
    "# dstr = datetime.today().strftime('%Y%m%d')\n",
    "# sds = df.reset_index().to_csv(index=False).split(split)\n",
    "# f = f'insitu_data_collection_{dstr}.csv'\n",
    "# with codecs.open(f, mode='w', encoding='utf-8') as txt:\n",
    "#     meta = sds.pop(0)\n",
    "#     txt.write(f'{meta}\\n')\n",
    "#     meta = meta.split(split)[0].split(',')\n",
    "    \n",
    "#     for i, line in enumerate(sds):\n",
    "#         li = line.split(split)[0].split(',')\n",
    "#         ret = fmt_output(iterator=zip(li, meta))\n",
    "#         str_fmt = ','.join(ret)\n",
    "#         if i == 1815:\n",
    "#             print(str_fmt)\n",
    "#         txt.write(f'{str_fmt}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc579ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1: (40, 1)\n",
    "# # 2: (57, 1)\n",
    "# # 2: (1426, 1)\n",
    "# # 3: (1544, 1)\n",
    "# # 3: (1813, 2)\n",
    "# # 3: (1813, 293)\n",
    "# # T: (1813, 293)\n",
    "# # ds1 = russia(file=flist[4]).reset_index()\n",
    "# # ds1 = ds1.set_index(['station', 'country'])\n",
    "# # ds2 = russia(file=flist[5]).reset_index()\n",
    "# # ds2 = ds2.set_index(['station', 'country'])\n",
    "# ds1 = russia(file=flist[4])\n",
    "# ds2 = russia(file=flist[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a4f4f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # for i in range(ds1.shape[0]):\n",
    "# #     idx = ds2.isin(ds1.loc[i, index].to_list())\n",
    "# #     break\n",
    "# # idx, ds2, ds1\n",
    "# out = ds1.merge(ds2, left_index=True, right_index=True, how='left')\n",
    "# out\n",
    "# df.merge(dfi, left_index=True, right_index=True, how='left')\n",
    "idx = df.reset_index()['country'].isin(['Japan'])\n",
    "df.reset_index().loc[idx, :].to_csv('text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec617a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
